{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "### First overall glance\n",
    "\n",
    "We first check the general look of the data.\\\n",
    "What is in front of us?\\\n",
    "How much data do we have?\\\n",
    "How is the data organized?\\\n",
    "What type of data is each part of?\n",
    "\n",
    "So we read the data with one line in pandas and\\\n",
    "get some overview with simple print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220320, 55)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('.\\pump_data\\pump_sensor.csv') # read data from csv file\n",
    "print(data.shape) # print the size of the data\n",
    "# print(data.keys()) # print the column names\n",
    "# print(data.head()) # print the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the print above we can derive that the CSV file\\\n",
    "contains 55 columns, with each over 200k entries.\n",
    "\n",
    "The data is separated into *52 sensor columns*, one\\\n",
    "*machine status (target/results) column*, a *timestamp column*,\\\n",
    "and one *Unnamed column*, which is just the original index column.\n",
    "\n",
    "From the timestamp we can see that the data is recorded\\\n",
    "in *1-minute steps*. The sensor data is in *float32* with\\\n",
    "varying aplitude and the timestamp is in the\\\n",
    "*yyyy-mm-dd hh:mm:ss format*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Data(y)\n",
    "\n",
    "The second most important thing is to take a look at the\\\n",
    "*target data (y data / results)*. This will give some\\\n",
    "indication for the solution strategy.\n",
    "\n",
    "After the first glimpse at the data, we have to check what\\\n",
    "*results (called target)* are provided which we can later use\\\n",
    "to identify/define our predictive maintenance goal/path.\n",
    "\n",
    "### Some questions about extracting the target data are :\n",
    "1. Do we have **target information**, or will it be an **unsupervised task**?\n",
    "2. Are the target data **continuous data** or **booleans**?\n",
    "3. What data type is the target in? **Values, text, …**\n",
    "4. In what intervals are the targets recorded?\\\n",
    "   Does every sensor entry get a **single entry**, or are they **grouped**?\n",
    "5. Does each sensor have its own target **(one machine — one sensor)**\\\n",
    "   or do we have one target for all sensors **(one machine — many sensors)**?\n",
    "6. Is the target **descriptive**, or do we have to identify what\\\n",
    "   counts as **broken** and what as **normal**?\n",
    "7. Is the target information complete and useful?\n",
    "\n",
    "To get some answers, we will get the unique classes and see how many\\\n",
    "values we have for each class. Finding, that the labels are in char\\\n",
    "format (text), we know, that we will have to convert them at some\\\n",
    "point into integer values to be useable for our later Ml algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status options: \n",
      "['NORMAL' 'BROKEN' 'RECOVERING']\n",
      "\n",
      "NORMAL        205836\n",
      "RECOVERING     14477\n",
      "BROKEN             7\n",
      "Name: machine_status, dtype: int64\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-77577b547385>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m '''\n\u001b[0;32m     22\u001b[0m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# get the label encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# fit the encoder to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mencoded_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# transform the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ursu\\AppData\\Local\\anaconda3\\envs\\stations\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \"\"\"\n\u001b[0;32m    100\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ursu\\AppData\\Local\\anaconda3\\envs\\stations\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_unique\u001b[1;34m(values, return_inverse)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \"\"\"\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unique_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;31m# numerical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ursu\\AppData\\Local\\anaconda3\\envs\\stations\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0muniques_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0muniques_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ursu\\AppData\\Local\\anaconda3\\envs\\stations\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_extract_missing\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mObject\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0minformation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     missing_values_set = {value for value in values\n\u001b[0m\u001b[0;32m     85\u001b[0m                           if value is None or is_scalar_nan(value)}\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ursu\\AppData\\Local\\anaconda3\\envs\\stations\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m<setcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m     84\u001b[0m     missing_values_set = {value for value in values\n\u001b[1;32m---> 85\u001b[1;33m                           if value is None or is_scalar_nan(value)}\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmissing_values_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "'''\n",
    "Get some info on the target-data\n",
    "'''\n",
    "# Get the unique values for the class\n",
    "print('status options: ')\n",
    "print(data['machine_status'].unique())\n",
    "print()\n",
    "\n",
    "# Count the number of each class\n",
    "print(data['machine_status'].value_counts())\n",
    "print()\n",
    "\n",
    "\n",
    "'''\n",
    "Convert the classes from string to values by using the scikit-learn mapper\n",
    "'''\n",
    "le = preprocessing.LabelEncoder() # get the label encoder\n",
    "le.fit(np.array(data)) # fit the encoder to the data # SOMETHING DOESNT WORK HERE\n",
    "encoded_y = pd.DataFrame(le.transform(data), columns=['target']) # transform the data\n",
    "\n",
    "# Get the Label map\n",
    "# To be able to later indentify what is what, create a label map\n",
    "# Same as:\n",
    "# le_name_mapping = {\n",
    "#     'BROKEN': 0,\n",
    "#     'NORMAL': 1,\n",
    "#     'RECOVERING': 2\n",
    "# }\n",
    "# zip() creates a list of tuples, where each tuple is a pair of elements\n",
    "# the elements are taken from the two lists given as arguments\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "\n",
    "'''\n",
    "Plot the target data\n",
    "'''\n",
    "x = np.linspace(1, len(encoded_y), len(encoded_y)) # create x-axis (could also be timestamp column)\n",
    "plt.plot(x, encoded_y)\n",
    "plt.ylabel('class')\n",
    "plt.title('Target data')\n",
    "labels = ['BROKEN', 'NORMAL', 'RECOVERING'] # Give the y-axis the Class lables we found earlier\n",
    "plt.yticks([1, 0, 2], labels, rotation='vertical') # Set the y-ticks to three to only show the classnames\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
