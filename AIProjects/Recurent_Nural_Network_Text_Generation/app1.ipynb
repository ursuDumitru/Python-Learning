{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Poetic Texts with Recurrent Neural Networks\n",
    "\n",
    "(https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/)\n",
    "\n",
    "Reccurent Neural Networks (RNNs) are a class of neural networks that is\n",
    "    powerful for modeling sequence data such as time series or natural\n",
    "    language. What distinguishes RNNs from other neural networks is that\n",
    "    they have a \"memory\" that captures information about what has been\n",
    "    calculated so far. In theory, RNNs can make use of information in\n",
    "    arbitrarily long sequences, but in practice they are limited to looking\n",
    "    back only a few steps. This is because the RNNs are trained by\n",
    "    \"unrolling\" them into very deep neural networks, which becomes\n",
    "    computationally expensive.\n",
    "\n",
    "LSTM is a type of Recurrent Neural Network (RNN) architecture that is very\n",
    "    effective in learning long-term dependencies. It has been successfully\n",
    "    applied to a variety of sequence modeling tasks, such as language\n",
    "    modeling, speech recognition, and text compression\n",
    "\n",
    "RMSprop is an unpublished, adaptive learning rate method proposed by Geoff\n",
    "    Hinton in Lecture 6e of his Coursera Class.\n",
    "Root Mean Square Propagation is an adaptive learning rate method, which\n",
    "    is a very effective technique for training neural networks. It is\n",
    "    especially effective for problems with sparse gradients, which is very\n",
    "    common in Natural Language Processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 134s 201ms/step - loss: 2.1499\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 56s 85ms/step - loss: 1.7217\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 55s 85ms/step - loss: 1.5934\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 57s 87ms/step - loss: 1.5247\n",
      "INFO:tensorflow:Assets written to: text_generator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_generator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "                                   'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "# .lower() is used to minimize the size of the data set\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "# select some part of the text\n",
    "text = text[300_000:800_000]\n",
    "# set is to select only unique characters\n",
    "characters = sorted(set(text))\n",
    "\n",
    "# create a dictionary to map characters to indices\n",
    "# enumerate() is used to iterate over a list and keep track of the index\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
    "\n",
    "# print(char_to_index) # examples : { ..., '?': 12, 'a': 13, ... }\n",
    "# print(index_to_char) # examples : { ..., 12: '?', 13: 'a', ... }\n",
    "\n",
    "# how many features(chars) we are going to use to predict the next character\n",
    "SEQ_LENGTH = 40\n",
    "# how many chars we are going to shift to create a new sequence\n",
    "# ????? Need more explanation for step_zise = 3:\n",
    "# ex: \"how are you\" -> \"ow are you \" -> \"w are you h\" -> \" are you ho\" -> \"are you how\"\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = [] # the input sentence , ex: \"how are yo\"\n",
    "next_characters = [] # the output character , ex: \"u\"\n",
    "\n",
    "# range(0, len(text) - SEQ_LENGTH, STEP_SIZE) ex: range(0, 100, 3) -> [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, ...]\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    # sentences are unfinished sequences of length SEQ_LENGTH\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    # and next characters are the SEQ_LENGTH-th character in the text\n",
    "    # which completes the sentence(the correct prediction)\n",
    "    next_characters.append(text[i + SEQ_LENGTH])\n",
    "\n",
    "'''\n",
    "nr_of_sentences x SEQ_LENGTH x nr_of_characters (3D array)\n",
    "1 dimension for all the possible sentences\n",
    "1 dimension for all the individual characters in a sentence\n",
    "1 dimension for all the possible characters in the text\n",
    "so if the character is present in the sentence\n",
    "x[sentence_index][character_index][character] = 1 otherwise 0\n",
    "'''\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool) # input\n",
    "# which character comes after a given sentence\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=bool) # output\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]] = 1\n",
    "    y[i, char_to_index[next_characters[i]]] = 1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# LSTM will remember the last 128 characters\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "# numberof neurons = number of characters\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax')) # softmax is used to normalize the output\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "# batch_size = how many sentences we are going to use for each training step\n",
    "model.fit(x, y, batch_size=256, epochs=4)\n",
    "\n",
    "model.save('text_generator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------0.2-----------------\n",
      "unish'd, that have minded you\n",
      "of what you the brack and the father thee\n",
      "and the hath the with the brother the brother stand thee the stands.\n",
      "\n",
      "king richard ii:\n",
      "the waster the heart to the stands of the stands.\n",
      "\n",
      "king richard ii:\n",
      "the true a stands and the the hath the brother,\n",
      "and the state have so the stands the brother both\n",
      "the brack the w\n",
      "-----------------0.4-----------------\n",
      "was forged, with my rapier's point.\n",
      "\n",
      "duke of york:\n",
      "the break in the morn to the hate and the traitor.\n",
      "\n",
      "first mayill:\n",
      "my lord, by the properate and the country.\n",
      "\n",
      "gloucester:\n",
      "the wonder's love to the fortune the with thee\n",
      "and the hath the batter so stands to the brother,\n",
      "and the heart to the speak the speak of shall for thee the winder\n",
      "and \n",
      "-----------------0.6-----------------\n",
      "s,\n",
      "no more my king, for he dishonours mersbled in thee\n",
      "is my slawn boying weeps in the great and the crastiless.\n",
      "\n",
      "king richard ii:\n",
      "i will thou killorn thee to the offerel no thee,\n",
      "that have and in the grown of and the death.\n",
      "o, but what whilrest is a should thou dost\n",
      "to revereing to the outrless, my lord, and there is laughter:\n",
      "and do loo\n",
      "-----------------0.8-----------------\n",
      "t so? or did i dream it so?\n",
      "or am i mad, my lords, sciteal too breeled\n",
      "speaks.\n",
      "\n",
      "hermiona:\n",
      "am you, the brothers that spite do now,\n",
      "what shought on to men with my strake!\n",
      "that hath thou threarny last and the brocks,\n",
      "when i noter a rogaur, who i do striftly beave\n",
      "addoness all 'cking hath resperence, and you, here.\n",
      "why, say, my father day a t\n",
      "-----------------1-----------------\n",
      "lies with swallow's wings:\n",
      "kings it make that us, o, his rohe.\n",
      "\n",
      "first look:\n",
      "ty't mine from the hate and drow underling oppringed,\n",
      "my lord that hardy margion with thee have hows on traitor.\n",
      "\n",
      "mowny:\n",
      "preckisl, devorse, i ridion, my lord, sta',\n",
      "ay no barkants are make the man, so you that my sages;\n",
      "and it is in worms as numper'd and your wors\n"
     ]
    }
   ],
   "source": [
    "model_load = tf.keras.models.load_model('text_generator.model')\n",
    "\n",
    "# The following function is used to generate the next character\n",
    "# based on the probability distribution of the output\n",
    "# temperature is used to control the randomness of the output\n",
    "# the higher the temperature the more random the output\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t , character in enumerate(sentence):\n",
    "            x[0, t, char_to_index[character]] = 1\n",
    "\n",
    "        predictions = model_load.predict(x, verbose=0)[0]\n",
    "        # print(predictions)\n",
    "        next_index = sample(predictions, temperature)\n",
    "        # print(next_index)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        # exclude the first character and add the next character at the end\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated\n",
    "\n",
    "print('-----------------0.2-----------------')\n",
    "print(generate_text(300, 0.2))\n",
    "print('-----------------0.4-----------------')\n",
    "print(generate_text(300, 0.4))\n",
    "print('-----------------0.6-----------------') # the best\n",
    "print(generate_text(300, 0.6))\n",
    "print('-----------------0.8-----------------') # or this one\n",
    "print(generate_text(300, 0.8))\n",
    "print('-----------------1-----------------')\n",
    "print(generate_text(300, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
